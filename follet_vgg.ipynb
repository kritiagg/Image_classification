{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning usingVGG Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 15,766,852\n",
      "Trainable params: 1,052,164\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kriti/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "model_vgg16_conv.summary()\n",
    "\n",
    "model_vgg16_conv.trainable = False\n",
    "#Create your own input format (here 3x200x200)\n",
    "\n",
    "input = Input(shape=(32,32,3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model_vgg16_conv(input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "\n",
    "x = Flatten(name='flatten',input_shape=(512,1,1))(output_vgg16_conv)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(512, activation='relu', name='fc2')(x)\n",
    "x = Dense(4, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=input, output=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Then training with your data ! \n",
    "\n",
    "for layer in my_model.layers[:2]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from scipy.misc import imshow\n",
    "import scipy.misc\n",
    "from numpy import *\n",
    "import PIL\n",
    "\n",
    "size = 32\n",
    "def preprocess_image(infilename,size):\n",
    "    data = Image.open(infilename)#.convert('L')\n",
    "#     data = scipy.misc.imread(infilename, mode = \"L\")\n",
    "    data.thumbnail((size,size), Image.ANTIALIAS)\n",
    "    img = data.resize((size,size))\n",
    "    scipy.misc.imsave(infilename, img)\n",
    "    \n",
    "def load_image( infilename ) :\n",
    "    data = scipy.misc.imread(infilename, mode = \"RGB\")\n",
    "#     preprocess_image(infilename,size)\n",
    "    return data\n",
    "\n",
    "path = ['Dataset/imgflip_images', 'Dataset/greetings_images','Dataset/scanned_documents','Dataset/imp_images']\n",
    "\n",
    "Y = []\n",
    "X = []\n",
    "data = []\n",
    "\n",
    "for p in path:\n",
    "    for files in listdir(p):\n",
    "        #print(files)\n",
    "        try:\n",
    "            t = load_image(p+'/'+files)\n",
    "            X = t\n",
    "            Y = (float(path.index(p)))\n",
    "            data.append((X,Y,p+'/'+files))\n",
    "        except:\n",
    "            print(\"error reading file:\"+ files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xtemp = np.uint8(X)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random.shuffle(data)\n",
    "imageNameDict = {}\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for d in data:\n",
    "    X.append(d[0])\n",
    "    Y.append(d[1])\n",
    "    imageNameDict[len(X)-1]=d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 32\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "totalSize = len(X)\n",
    "trainingSize = int(0.8*totalSize)\n",
    "# load data\n",
    "X_train = np.array(X[:trainingSize])\n",
    "y_train = np.array(Y[:trainingSize])\n",
    "X_test = np.array(X[trainingSize:])\n",
    "y_test = np.array(Y[trainingSize:])\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "# X_train = X_train.reshape(X_train.shape[0], 3, image_size, image_size).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], 3, image_size, image_size).astype('float32')\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "15742\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import History \n",
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15742 samples, validate on 3936 samples\n",
      "Epoch 1/20\n",
      "15742/15742 [==============================] - 518s - loss: 0.5966 - acc: 0.7622 - val_loss: 0.4763 - val_acc: 0.8143\n",
      "Epoch 2/20\n",
      "15742/15742 [==============================] - 516s - loss: 0.4411 - acc: 0.8308 - val_loss: 0.4555 - val_acc: 0.8178\n",
      "Epoch 3/20\n",
      "15742/15742 [==============================] - 527s - loss: 0.3827 - acc: 0.8534 - val_loss: 0.4113 - val_acc: 0.8488\n",
      "Epoch 4/20\n",
      "15742/15742 [==============================] - 532s - loss: 0.3281 - acc: 0.8769 - val_loss: 0.4516 - val_acc: 0.8364\n",
      "Epoch 5/20\n",
      "15742/15742 [==============================] - 525s - loss: 0.2920 - acc: 0.8919 - val_loss: 0.3980 - val_acc: 0.8623\n",
      "Epoch 6/20\n",
      "15742/15742 [==============================] - 532s - loss: 0.2438 - acc: 0.9109 - val_loss: 0.4116 - val_acc: 0.8605\n",
      "Epoch 7/20\n",
      "15742/15742 [==============================] - 526s - loss: 0.2019 - acc: 0.9287 - val_loss: 0.3992 - val_acc: 0.8737\n",
      "Epoch 8/20\n",
      "15742/15742 [==============================] - 556s - loss: 0.1826 - acc: 0.9346 - val_loss: 0.4825 - val_acc: 0.8359\n",
      "Epoch 9/20\n",
      "15742/15742 [==============================] - 638s - loss: 0.1555 - acc: 0.9444 - val_loss: 0.4410 - val_acc: 0.8681\n",
      "Epoch 10/20\n",
      "15742/15742 [==============================] - 544s - loss: 0.1222 - acc: 0.9574 - val_loss: 0.4530 - val_acc: 0.8745\n",
      "Epoch 11/20\n",
      "15742/15742 [==============================] - 584s - loss: 0.1104 - acc: 0.9609 - val_loss: 0.4664 - val_acc: 0.8778\n",
      "Epoch 12/20\n",
      "15742/15742 [==============================] - 555s - loss: 0.0911 - acc: 0.9674 - val_loss: 0.4986 - val_acc: 0.8605\n",
      "Epoch 13/20\n",
      "15742/15742 [==============================] - 540s - loss: 0.0796 - acc: 0.9719 - val_loss: 0.5344 - val_acc: 0.8819\n",
      "Epoch 14/20\n",
      "15742/15742 [==============================] - 525s - loss: 0.0513 - acc: 0.9833 - val_loss: 0.6004 - val_acc: 0.8613\n",
      "Epoch 15/20\n",
      "15742/15742 [==============================] - 531s - loss: 0.0504 - acc: 0.9823 - val_loss: 0.6263 - val_acc: 0.8610\n",
      "Epoch 16/20\n",
      "15742/15742 [==============================] - 537s - loss: 0.0399 - acc: 0.9876 - val_loss: 0.6475 - val_acc: 0.8758\n",
      "Epoch 17/20\n",
      "15742/15742 [==============================] - 522s - loss: 0.0368 - acc: 0.9881 - val_loss: 0.6330 - val_acc: 0.8760\n",
      "Epoch 18/20\n",
      "15742/15742 [==============================] - 521s - loss: 0.0360 - acc: 0.9883 - val_loss: 0.6776 - val_acc: 0.8745\n",
      "Epoch 19/20\n",
      "15742/15742 [==============================] - 528s - loss: 0.0419 - acc: 0.9862 - val_loss: 0.6920 - val_acc: 0.8798\n",
      "Epoch 20/20\n",
      "15742/15742 [==============================] - 541s - loss: 0.0425 - acc: 0.9857 - val_loss: 0.6814 - val_acc: 0.8725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa50e63a908>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "weights_file = 'models/vgg_exp1.h5'\n",
    "if not os.path.exists(weights_file):\n",
    "#     my_model.compile(optimizer = 'adam',loss= 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    my_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=200, callbacks = [history])    \n",
    "    my_model.save_weights(weights_file)\n",
    "else:\n",
    "    my_model.load_weights(weights_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "my_model.save_weights(weights_file)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot(label1,label2,xlabel,ylabel):\n",
    "    X_axis = range(1,len(acc)+1)\n",
    "    plt.plot(X_axis, acc, marker='o', linestyle='-', color='g',label=xlabel)\n",
    "    plt.plot(X_axis, val_acc, marker='o', linestyle='--', color='r',label=ylabel)\n",
    "    plt.xlabel(label1)\n",
    "    plt.ylabel(label2)\n",
    "    legend = plt.legend(loc='lower right', shadow=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot('No. of epochs','Accuracy',\"Train Accuracy\",\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predict = model.predict(X_test, verbose=1)\n",
    "predict1 = np.argmax(predict,axis=1)\n",
    "y_test1 = np.argmax(y_test,axis=1)\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm= confusion_matrix(y_test1,predict1)\n",
    "print(cm)\n",
    "sn.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.imshow(cm, cmap='binary')\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "categories = [\"memes\",'greetings','scanned','misc']\n",
    "np.set_printoptions(suppress=True)\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in categories],\n",
    "                  columns = [i for i in categories])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misclassified = np.where(y_test1 != predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "misclassified_files = []\n",
    "for i in misclassified[0]:\n",
    "    print(\"backup/\"+imageNameDict[i])\n",
    "    misclassified_files.append(\"backup/\"+imageNameDict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'misclassified_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-10ff15e540c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclassified_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label:\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmisclassified\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'misclassified_files' is not defined"
     ]
    }
   ],
   "source": [
    "img = Image.open(misclassified_files[0])\n",
    "plt.imshow(img)\n",
    "print(\"Label:\"+ y_test[int(misclassified[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
